{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Jetson Inferencing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import jetson.inference\n",
    "import jetson.utils\n",
    "\n",
    "# NOT USED AT THE MOMENT\n",
    "\n",
    "# Should get ~39 FPS\n",
    "network = 'ssd-mobilenet-v2'\n",
    "overlay = 'box,labels,conf'\n",
    "threshold = 0.5\n",
    "c_width = \"244\"\n",
    "c_height = \"244\"\n",
    "\n",
    "args = \"--network {} --overlay {} --camera {} --width {} --height {}\".format(network, overlay, \"0\", c_width, c_height)\n",
    "\n",
    "# load the recognition network\n",
    "#net = jetson.inference.detectNet(network, args, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camera import Camera\n",
    "from CV_FIND import CV_IMG_PROCESSOR\n",
    "\n",
    "width = int(244)\n",
    "height = int(244)\n",
    "#camera = cv2.VideoCapture(0) # FOR USB WEBCAM\n",
    "camera = Camera(width=width, height=height, capture_width=1280, capture_height=720, capture_fps=60, capture_flip=2)\n",
    "main_cv = CV_IMG_PROCESSOR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect User Data\n",
    "#### Initialize Training Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/vikram/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/vikram/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/vikram/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/vikram/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/vikram/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/vikram/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vikram/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 80, 80, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 19, 19, 32)        2080      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 64)          32832     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "Q_Values (Dense)             (None, 19)                4883      \n",
      "=================================================================\n",
      "Total params: 666,803\n",
      "Trainable params: 666,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#from agent import DDPG\n",
    "from DQN import DQNAgent\n",
    "img_shape_1 = (80,80,1) # 40,60\n",
    "action_size = 19\n",
    "car_agent = DQNAgent(img_shape_1, action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6c80e346c04aaaa3a5e3ff3772b479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='122.0', width='244')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widget_test = ipywidgets.Image(format='jpeg', width=width, height=height/2)\n",
    "display(widget_test)\n",
    "def update_images():\n",
    "\n",
    "    img = camera.value\n",
    "    main_cv.getSteering(img,\"canny\")\n",
    "    img2 = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2GRAY)\n",
    "    img2 = cv2.resize(img2, (80,80)) # 60,40\n",
    "    main_cv.preprocessed_img = img2/255\n",
    "    main_cv.raw_img = img\n",
    "    main_cv.flag = True\n",
    "\n",
    "#car_agent.noise.mu = 0 * np.ones(1)\n",
    "#car_agent.noise.reset()\n",
    "\n",
    "# CAM TESTING\n",
    "for i in range(0,30):\n",
    "    update_images()\n",
    "    action = np.argmax(car_agent.model.predict(car_agent.conv_to_tensor(main_cv.preprocessed_img)))*10\n",
    "    preview = np.squeeze(main_cv.preprocessed_img)*255  \n",
    "    widget_test.value = bgr8_to_jpeg(preview)\n",
    "    \n",
    "# View convolution layer (experimental)\n",
    "if(0):\n",
    "    test = car_agent.get_conv([car_agent.conv_to_tensor(resized_img)]).reshape(32,9,14)\n",
    "    print(test.shape)\n",
    "\n",
    "    row = 8\n",
    "    col = 4\n",
    "    ix = 1\n",
    "    for _ in range(row):\n",
    "        for _ in range(col):\n",
    "            # specify subplot and turn of axis\n",
    "            ax = plt.subplot(row, col, ix)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            # plot filter channel in grayscale\n",
    "            plt.imshow(test[ix], cmap='gray')\n",
    "            ix += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp((-9*x)+4))\n",
    "\n",
    "def tan(x):\n",
    "    return -np.tanh((4*x)-2)\n",
    "\n",
    "def tight_tan(x):\n",
    "    return -np.tanh((15*x)-3)\n",
    "\n",
    "def tan2(x):\n",
    "     return -np.tanh((3*x)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# For plotting while training\n",
    "def episodic_plot(in_matrix, title=\"Loss\"):\n",
    "    fig2 = plt.figure()\n",
    "    ax1 = plt.axes()\n",
    "    fig2.set_size_inches(15,5)\n",
    "    ax1.set_title(title)\n",
    "    for i, p in enumerate(in_matrix):\n",
    "        ax1.plot(p, label=i)\n",
    "    ax1.legend()\n",
    "    \n",
    "BENCHMARK = True\n",
    "SHOW_LIVE = True\n",
    "\n",
    "if(BENCHMARK):\n",
    "    loop_times = []\n",
    "all_times = []    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "Paused 5\n",
      "Start\n",
      "Paused 6\n",
      "Start\n",
      "Paused 7\n",
      "Start\n",
      "Paused 8\n",
      "Start\n",
      "Paused 9\n",
      "Start\n",
      "Paused 10\n",
      "Start\n",
      "Paused 11\n",
      "Start\n",
      "Paused 12\n",
      "Start\n",
      "Paused 13\n",
      "Start\n",
      "Paused 14\n",
      "Start\n",
      "Paused 15\n",
      "Start\n",
      "Paused 16\n",
      "Start\n",
      "Paused 17\n",
      "Start\n",
      "Paused 18\n",
      "Start\n",
      "Paused 19\n",
      "Start\n",
      "Paused 20\n",
      "EXIT\n",
      "average(sec):0.02, fps:41.60, train_time 2273.351768\n"
     ]
    }
   ],
   "source": [
    "from approxeng.input.selectbinder import ControllerResource\n",
    "from IPython.display import display, clear_output\n",
    "import random as rn\n",
    "import serial\n",
    "\n",
    "# PI Cam 160 FOV 60 FPS @ 1280x720 (GSTREAMER SAYS 120?)\n",
    "with serial.Serial('/dev/ttyUSB0', 1000000, timeout=1) as ser:\n",
    "    with ControllerResource() as joystick:\n",
    "        CONST_TIME = 0.017\n",
    "        P = 4\n",
    "        D = 0.03\n",
    "        error_old = 0\n",
    "        \n",
    "        # Initialize\n",
    "        TRAIN = False\n",
    "        count = 1\n",
    "        STEERING = 90\n",
    "        THROTTLE = 90\n",
    "        update_images()\n",
    "        \n",
    "        state = main_cv.preprocessed_img\n",
    "        next_state = main_cv.preprocessed_img\n",
    "        action = 0\n",
    "        reward = 0\n",
    "        \n",
    "        DEBUG = 0\n",
    "        mse_arr = []\n",
    "        MSE = 0\n",
    "        start_time = 0\n",
    "        loop_start = 0\n",
    "        option = 0b000\n",
    "        AUTO_THROTTLE = False\n",
    "        total_time = 0\n",
    "        speed = 0\n",
    "        \n",
    "        while joystick.connected:\n",
    "            if(BENCHMARK):\n",
    "                start_time = time.time()\n",
    "            \n",
    "            if(joystick['cross'] is not None):  # SQUARE EXIT\n",
    "                print(\"EXIT\")\n",
    "                output = \"{:05d}-{:05d}\\n\".format(int(90), int(90))\n",
    "                ser.write(bytes(output,'utf-8'))\n",
    "                ser.close()\n",
    "                break\n",
    "                \n",
    "            if(joystick['triangle'] is not None):  # TRIANGLE TOGGLE TRAIN\n",
    "                if(DEBUG == False):\n",
    "                    if(TRAIN):\n",
    "                        all_times.append((time.time()-loop_start))\n",
    "                        total_time = sum(all_times)\n",
    "                        print(\"Paused\", len(all_times))\n",
    "                        option &= 0b110  # clear 3rd bit\n",
    "                        TRAIN = False   \n",
    "                    else:\n",
    "                        option |= 0b001 # set 3rd bit\n",
    "                        print(\"Start\")\n",
    "                        TRAIN = True\n",
    "                        loop_start = time.time()\n",
    "                    state = main_cv.preprocessed_img\n",
    "                    time.sleep(0.2)\n",
    "                    count = 1\n",
    "                else:\n",
    "                    print(\"Cannot train while debug\")\n",
    "                \n",
    "                \n",
    "            if(joystick['circle'] is not None):  # X DEBUG. WILL NOT MODIFY NETWORK\n",
    "                if(DEBUG):\n",
    "                    option &= 0b101 # clear 2nd\n",
    "                    DEBUG = False   \n",
    "\n",
    "                else:\n",
    "                    option |= 0b010 # set 2nd\n",
    "                    if(TRAIN):\n",
    "                        all_times.append((time.time()-loop_start))\n",
    "                        print(\"Timer paused while debug\")\n",
    "                        total_time = sum(all_times)\n",
    "                        option &= 0b110  # clear 3rd bit train off\n",
    "                        TRAIN = False\n",
    "                    DEBUG = True\n",
    "                state = main_cv.preprocessed_img\n",
    "                time.sleep(0.2)\n",
    "                count = 1\n",
    "                \n",
    "            if(joystick['square'] is not None):# LB for auto-throttle\n",
    "                if(AUTO_THROTTLE):\n",
    "                    option &= 0b011  # clear 1st\n",
    "                    AUTO_THROTTLE = False\n",
    "                else:\n",
    "                    option |= 0b100  # set 1st\n",
    "                    AUTO_THROTTLE = True\n",
    "                time.sleep(0.2)\n",
    "                \n",
    "            # Update CV calc and images\n",
    "            update_images()\n",
    "                \n",
    "            # PD Calculations\n",
    "            error = (main_cv.angle-90) # -90 0 90 ERR\n",
    "            P_T = error * P\n",
    "            D_T = ((error-error_old)/CONST_TIME)*D\n",
    "            cv_action = int(np.clip(((P_T-D_T)+90), 2, 178))\n",
    "            error_old = error\n",
    "            \n",
    "            act_values = car_agent.model.predict(car_agent.conv_to_tensor(main_cv.preprocessed_img))\n",
    "            agent_action = np.argmax(act_values[0])*10\n",
    "            correct_action_value = act_values[0][int((cv_action/10))]\n",
    "            predicted_value = act_values[0][np.argmax(act_values[0])]\n",
    "            \n",
    "            # Default\n",
    "            THROTTLE = int((joystick['ly']+1)/2*180)\n",
    "            #STEERING = int((joystick['rx']+1)/2*180)\n",
    "\n",
    "            # Value used for training\n",
    "            train_STEER = agent_action\n",
    "            if(TRAIN):\n",
    "                # EXPLORATION\n",
    "                if(count%5 == 0):  # \"Random\" good sample\n",
    "                    chance = rn.randint(0, 9)\n",
    "                    if(chance == 9): # \n",
    "                        train_STEER = rn.randint(2, 178)\n",
    "                    else: # \n",
    "                        train_STEER = cv_action\n",
    "                        \n",
    "\n",
    "                if(AUTO_THROTTLE):\n",
    "                    if(STEERING < 30 or STEERING > 160): # to avoid getting stuck in tight corner\n",
    "                        THROTTLE = 150\n",
    "                        \n",
    "            # OUTPUT CONTROL DEFAULT; Changes after model has stabilized\n",
    "            STEERING = agent_action\n",
    "            if(AUTO_THROTTLE):\n",
    "                THROTTLE = int(-160) # RPM\n",
    "                   \n",
    "            # Some manual \n",
    "            if(joystick['l1'] is not None):# L trigger for manual\n",
    "                STEERING = int((joystick['rx']+1)/2*180)\n",
    "                THROTTLE = int((joystick['ly']+1)/2*180)\n",
    "\n",
    "            '''\n",
    "            # DEFAULT \n",
    "                TRAINING OFF\n",
    "                USER IN CONTROL\n",
    "                \n",
    "            # TRAIN\n",
    "                TRAINING MODEL\n",
    "                CV IN CONTROL\n",
    "                \n",
    "            # DEBUG MODE (TRAIN ON)\n",
    "                TRAINING OFF\n",
    "                VIEW STATE UPDATES, MSE\n",
    "                VIEW THE Q TABLE\n",
    "            '''\n",
    "            \n",
    "            if(TRAIN or DEBUG):\n",
    "                next_state = main_cv.preprocessed_img\n",
    "                if(count % 5 == 0): # Frame Skipping\n",
    "                    if(DEBUG == 0):\n",
    "                        target = reward + car_agent.gamma * \\\n",
    "                           np.amax(car_agent.target_model.predict(car_agent.conv_to_tensor(next_state))[0])\n",
    "                        target_f = car_agent.target_model.predict(car_agent.conv_to_tensor(state))\n",
    "                        target_f[0][int(action/10)] = target\n",
    "                        car_agent.model.fit(car_agent.conv_to_tensor(state), target_f, epochs=1, verbose=0)\n",
    "                        car_agent.batch_id += 1\n",
    "                        \n",
    "                        # TAU UPDATE\n",
    "                        if(count % 60 == 0):\n",
    "                            car_agent.target_train()\n",
    "                        \n",
    "                    # SARSA at this moment (for STATE)\n",
    "                    state = next_state.copy()\n",
    "                    action = train_STEER\n",
    "                    reward = tight_tan(abs(train_STEER-cv_action)/180) \n",
    "                count += 1                   \n",
    "                \n",
    "            # Performance indicator\n",
    "            if(count % 30 == 0):\n",
    "                if(len(mse_arr) < 30):\n",
    "                    mse_arr.append((agent_action-cv_action)**2)\n",
    "                    MSE = np.mean(mse_arr)\n",
    "                else:\n",
    "                    mse_arr.clear()\n",
    "                \n",
    "            if(SHOW_LIVE):\n",
    "                output = \"{:05d}-{:05d}\\n\".format(int(THROTTLE), int(STEERING))\n",
    "                ser.write(bytes(output,'utf-8'))\n",
    "                time.sleep(0.001)\n",
    "                speed_in = (ser.readline())\n",
    "                if speed_in:\n",
    "                    speed = speed_in\n",
    "                    \n",
    "                info_str = \"SPEED {:1d} Predict {:1d} CV {:1.3f} TIME {:1.2f}\".format(int(speed), int(agent_action), cv_action, total_time)\n",
    "                second_line = \"MEM {:1d} ID {:1d} VAL {:1.4f} AGNT = {:1.4f}\".format(len(car_agent.memory), car_agent.batch_id, correct_action_value, predicted_value)\n",
    "                third_line = \"Reward {:1.3f} ACTION {:1d} MSE {:1.3f}\".format(reward, int(action/10), MSE)\n",
    "                fourth_line = \"State [Throttle,Debug,Train]: {0:03b}\".format(option)\n",
    "                \n",
    "                if(DEBUG):\n",
    "                    # Need to find another way..\n",
    "                    clear_output(wait=True)\n",
    "                    for i, j in enumerate(act_values[0]):\n",
    "                        print(\"{:1d} {:02.5f}   \".format(i,j),end=\" \")\n",
    "                \n",
    "                if(TRAIN):\n",
    "                    preview = (cv2.resize(state, (244,244)).copy())*255\n",
    "                else:\n",
    "                    preview = main_cv.preview_img\n",
    "                    #preview = cv2.cvtColor(main_cv.raw_img, cv2.COLOR_BGR2GRAY)\n",
    "                    \n",
    "                cv2.putText(preview, info_str, (0, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 0, 0))\n",
    "                cv2.putText(preview, second_line, (0, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 0, 0))\n",
    "                cv2.putText(preview, third_line, (0, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 0, 0))\n",
    "                cv2.putText(preview, fourth_line, (0, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 0, 0))\n",
    "\n",
    "                cv2.circle(preview, (int(main_cv.line[0]), int(122)), 4, (255,0,0),  -1)\n",
    "                widget_train.value = bgr8_to_jpeg(preview)\n",
    "\n",
    "            if(BENCHMARK):\n",
    "                delta = (time.time() - start_time)\n",
    "                loop_times.append(delta)\n",
    "            \n",
    "if(BENCHMARK):\n",
    "    mean_delta = np.array(loop_times).mean()\n",
    "    fps = 1 / mean_delta\n",
    "\n",
    "    print('average(sec):{:.2f}, fps:{:.2f}, train_time {:2f}'.format(mean_delta, fps, total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cv.arc_length_min = 170\n",
    "main_cv.canny_min = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c54429c9c34bcc8959ae0a75fec26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='122.0', width='244')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NEED TO RUN THIS CELL BEFORE ABOVE ONE\n",
    "if(SHOW_LIVE):\n",
    "    widget_train = ipywidgets.Image(format='jpeg', width=width, height=height/2)\n",
    "    display(widget_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d96e3da29944edad2902e3c3cfe35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='122.0', width='244')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENT ACTIVE\n",
      "AGENT OFF\n",
      "EXIT\n",
      "average(sec):0.01, fps:74.56\n"
     ]
    }
   ],
   "source": [
    "from approxeng.input.selectbinder import ControllerResource\n",
    "from IPython.display import display, clear_output\n",
    "import random as rn\n",
    "import serial\n",
    "\n",
    "widget_test = ipywidgets.Image(format='jpeg', width=width, height=height/2)\n",
    "display(widget_test)\n",
    "RECORD = True\n",
    "Frames = []\n",
    "speeds = []\n",
    "\n",
    "# PI Cam 160 FOV 60 FPS @ 1280x720 (GSTREAMER SAYS 120?)\n",
    "with serial.Serial('/dev/ttyUSB0', 1000000, timeout=1) as ser:\n",
    "    with ControllerResource() as joystick:\n",
    "        # Initialize\n",
    "        STEERING = 90\n",
    "        THROTTLE = 90\n",
    "        ACTIVE = False\n",
    "        times = []\n",
    "        \n",
    "        while joystick.connected:\n",
    "            if(BENCHMARK):\n",
    "                start_time = time.time()\n",
    "                \n",
    "            if(joystick['cross'] is not None):  # SQUARE EXIT\n",
    "                print(\"EXIT\")\n",
    "                ser.close()\n",
    "                break\n",
    "                \n",
    "            if(joystick['triangle'] is not None):  # TRIANGLE TOGGLE AGENT\n",
    "                if(ACTIVE):\n",
    "                    print(\"AGENT OFF\")\n",
    "                    ACTIVE = False   \n",
    "                else:\n",
    "                    print(\"AGENT ACTIVE\")\n",
    "                    ACTIVE = True\n",
    "                time.sleep(0.2)\n",
    "                \n",
    "            image = (camera.value)\n",
    "            img_gray = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY)\n",
    "            img2 = cv2.resize(img_gray, (80,80))/255 # 60,40\n",
    "            \n",
    "            act_values = car_agent.model.predict(car_agent.conv_to_tensor(img2))\n",
    "            agent_action = np.argmax(act_values[0])*10\n",
    "            \n",
    "            # Default\n",
    "            THROTTLE = int((joystick['ly']+1)/2*180)\n",
    "            STEERING = int((joystick['rx']+1)/2*180)\n",
    "            \n",
    "            if(ACTIVE):\n",
    "                STEERING = agent_action\n",
    "                THROTTLE = int(-160)\n",
    "                \n",
    "            # Manual \n",
    "            if(joystick['l1'] is not None):# L trigger for manual\n",
    "                STEERING = int((joystick['rx']+1)/2*180)\n",
    "                THROTTLE = int((joystick['ly']+1)/2*180)\n",
    "                \n",
    "            if(SHOW_LIVE):\n",
    "                output = \"{:05d}-{:05d}\\n\".format(int(THROTTLE), int(STEERING))\n",
    "                ser.write(bytes(output,'utf-8'))\n",
    "                speed = (ser.readline())\n",
    "                if not speed:\n",
    "                    speed = 0\n",
    "                    \n",
    "                info_str = \"SPEED {:1d} PREDICT {:1d}\".format(int(speed), int(agent_action))\n",
    "            \n",
    "                preview = img_gray\n",
    "                cv2.putText(preview, info_str, (0, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 0, 0))\n",
    "\n",
    "                cv2.circle(preview, (int(main_cv.line[0]), int(122)), 4, (255,0,0),  -1)\n",
    "                widget_test.value = bgr8_to_jpeg(preview)\n",
    "                \n",
    "                if(RECORD):\n",
    "                    Frames.append(preview)\n",
    "                    speeds.append(int(speed))\n",
    "\n",
    "            if(BENCHMARK):\n",
    "                delta = (time.time() - start_time)\n",
    "                times.append(delta)\n",
    "            \n",
    "if(BENCHMARK):\n",
    "    mean_delta = np.array(times).mean()\n",
    "    fps = 1 / mean_delta\n",
    "    print('average(sec):{:.2f}, fps:{:.2f}'.format(mean_delta, fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7ed819a1a94b5d937fcb8358982ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='122.0', width='244')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEED AVG 259.2234161988773\n"
     ]
    }
   ],
   "source": [
    "preview_widget = ipywidgets.Image(format='jpeg', width=width, height=height/2)\n",
    "display(preview_widget)\n",
    "print(\"SPEED AVG\", np.mean(speeds))\n",
    "\n",
    "out = cv2.VideoWriter(\"dqn.avi\",cv2.VideoWriter_fourcc(*\"MJPG\"), 80,(width,height),0)\n",
    "for f in Frames:\n",
    "    out.write(f.astype('uint8'))\n",
    "    preview_widget.value = bgr8_to_jpeg(f)\n",
    "    \n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESTART CAM\n",
    "camera.unobserve_all()\n",
    "camera.stop()\n",
    "time.sleep(2)\n",
    "#camera = Camera(width=width, height=height, capture_width=1280, capture_height=720, capture_fps=60, capture_flip=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve_all()\n",
    "camera.stop()\n",
    "car_agent.memory.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_agent.model.save(\"./model/DQN_BEST4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
